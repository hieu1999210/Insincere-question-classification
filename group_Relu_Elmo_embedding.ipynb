{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "group_Relu_Elmo_embedding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hieu1999210/Insincere-question-classification/blob/master/group_Relu_Elmo_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndTYK0Paz9Cc",
        "colab_type": "code",
        "outputId": "6017e9a5-169d-41b5-b4c9-b9042d4d6bf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!pip install h5py pyyaml\n",
        "# !pip install tf_nightly"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJnknIR50QL6",
        "colab_type": "code",
        "outputId": "bd622648-be38-4349-dc4f-94fbfa628281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeXb870NbiBZ",
        "colab_type": "code",
        "outputId": "7fc90503-490c-4531-a94d-c502efb88539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNqTc7XXbrkB",
        "colab_type": "text"
      },
      "source": [
        "### Load and preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcyBknnpbwy7",
        "colab_type": "code",
        "outputId": "fc2721d8-386c-4b16-c207-dc793873023c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# mount hieu.kaggle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=False)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsR9l5TidLEN",
        "colab_type": "code",
        "outputId": "46302373-b556-482c-d983-c1057e3837ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd \"/gdrive/My Drive/nlp\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/nlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo-oFoZB7MkI",
        "colab_type": "code",
        "outputId": "9f147d3f-c17f-4c47-9410-80bb73c87e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  embeddings  training_elmo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnoGR-5wb59R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "\n",
        "path_train = \"data/train.csv\"\n",
        "path_test = \"data/test.csv\"\n",
        "train = pd.read_csv(path_train)\n",
        "test = pd.read_csv(path_test)\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1396XLvcLM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val = train_test_split(train, test_size = 0.01, random_state = 2019) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4jsjFEMnZxI",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Some parameters\n",
        "embedding_dim = 1024 #@param {type:\"integer\"}\n",
        "\n",
        "vocab_size = 50000 #@param {type:\"integer\"}\n",
        "\n",
        "question_length = 100 #@param {type:\"integer\"}\n",
        "\n",
        "batch_size = 256 #@param {type:\"integer\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usF0cVqynQDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## fill up the missing values\n",
        "train_X = train[\"question_text\"].fillna(\"_na_\").values\n",
        "val_X = val[\"question_text\"].fillna(\"_na_\").values\n",
        "test_X = test[\"question_text\"].fillna(\"_na_\").values\n",
        "\n",
        "#Tokenize the sentences\n",
        "# tokenizer = Tokenizer(num_words = max_features)\n",
        "# tokenizer.fit_on_texts(list(train_X))\n",
        "# train_X = tokenizer.texts_to_sequences(train_X)\n",
        "# val_X = tokenizer.texts_to_sequences(val_X)\n",
        "# test_X = tokenizer.texts_to_sequences(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdEQ1HDun3_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #padding\n",
        "# train_X = pad_sequences(train_X, maxlen = maxlen)\n",
        "# val_X = pad_sequences(val_X, maxlen = maxlen)\n",
        "# test_X = pad_sequences(test_X, maxlen = maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjLCoQMu1eCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = train['target'].values\n",
        "val_y = val['target'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_UXCL0TcOBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QvXhqjBnNuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#padding\n",
        "\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "def padding(sentences, maxlen= question_length, pad_word = \"\"):\n",
        "    \"\"\"\n",
        "    padding sentences and truncating if necessary\n",
        "    \"\"\"\n",
        "    Sentences = [text_to_word_sequence(sentence, lower = False, split=' ') for sentence in sentences]\n",
        "#     lengths = []\n",
        "    for i, sentence in enumerate(Sentences):\n",
        "#         lengths.append(len(sentence))\n",
        "        if len(sentence) > maxlen:\n",
        "            Sentences[i] = sentence[:maxlen]\n",
        "        else:\n",
        "            for _ in range(maxlen - len(sentence)):\n",
        "                sentence.append(pad_word)\n",
        "    return Sentences\n",
        "\n",
        "train_X = padding(train_X)\n",
        "val_X = padding(val_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYIba4b-Aaf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to run on tpu\n",
        "\n",
        "\n",
        "# def train_input_fn(x_train=train_X, y_train=train_y, batch_size=batch_size):\n",
        "#     # Convert the inputs to a Dataset.\n",
        "#     dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "# # Shuffle, repeat, and batch the examples.\n",
        "#     dataset = dataset.cache()\n",
        "#     dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)\n",
        "#     dataset = dataset.repeat()\n",
        "#     dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "# # Return the dataset.\n",
        "#     return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GichFDCrAhOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tpu_val = train_input_fn(val_X, val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc2OvkqzBa9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tpu_train = train_input_fn(train_X, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmPXHrG-eazK",
        "colab_type": "code",
        "outputId": "323da1b4-6b62-4726-b4b5-a4dbf310b281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test padding\n",
        "count = 0\n",
        "for sentence in val_X:\n",
        "    if len(sentence) != 100:\n",
        "        count +=1\n",
        "count"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQuAlFb5BEVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to enable  tpu\n",
        "\n",
        "\n",
        "# import sys\n",
        "\n",
        "# # sys.path.append('bert/')\n",
        "\n",
        "# from __future__ import absolute_import\n",
        "# from __future__ import division\n",
        "# from __future__ import print_function\n",
        "\n",
        "# import codecs\n",
        "# import collections\n",
        "# import json\n",
        "# import re\n",
        "# import os\n",
        "# import pprint\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "\n",
        "# assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "# TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "# print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "# with tf.Session(TPU_ADDRESS) as session:\n",
        "#   print('TPU devices:')\n",
        "#   pprint.pprint(session.list_devices())\n",
        "\n",
        "#   # Upload credentials to TPU.\n",
        "#   with open('/content/adc.json', 'r') as f:\n",
        "#     auth_info = json.load(f)\n",
        "#   tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "#   # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8qBebeudXSB",
        "colab_type": "text"
      },
      "source": [
        "### Generate batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBgTX0o6ryHt",
        "colab_type": "text"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHsYCxxXsEMM",
        "colab_type": "text"
      },
      "source": [
        "import elmo \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWSkYnpRct8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndYG6HBlip1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICrNegJHkJD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def ElmoEmbedding(x):\n",
        "    return elmo(inputs={\"tokens\": tf.squeeze(tf.cast(x,tf.string)),\n",
        "                        \"sequence_len\": tf.constant(batch_size*[question_length])},\n",
        "                signature=\"tokens\",\n",
        "                as_dict=True)[\"elmo\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEDHB4RrbCQQ",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG8Qoo3KPXND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(y_true * y_pred)\n",
        "        possible_positives = K.sum(y_true)\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(y_true * y_pred)\n",
        "        predicted_positives = K.sum(y_pred)\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    \n",
        "    Y_pred = tf.cast(tf.less(0.3, y_pred), tf.float32)\n",
        "    \n",
        "    precision = precision(y_true, Y_pred)\n",
        "    recall = recall(y_true, Y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro9u2r19FPZy",
        "colab_type": "code",
        "outputId": "63345827-85d6-4709-875d-1b6be1745203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.keras.__version__)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayc_EjMHlJrb",
        "colab_type": "code",
        "outputId": "4c6d2957-5665-4acb-f69b-55aaa5d7ea94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Lambda, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "def build_model ():\n",
        "# model = Sequential()\n",
        "# model.add(Lambda(ElmoEmbedding, output_shape = (1024, )))\n",
        "# #model.add(Embedding(50000, 300, input_length=100, trainable=True))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Conv1D(64, 5, activation='relu'))\n",
        "# model.add(MaxPooling1D(pool_size=4))\n",
        "# model.add(LSTM(300))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# model.build(input_shape = (None, 100, 1024))\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "  input_text = Input(shape=(question_length,) , dtype = tf.string)\n",
        "  embedding = Lambda(ElmoEmbedding, output_shape=(question_length, embedding_dim))(input_text)\n",
        "  x = Dropout(rate = 0.2)(embedding)\n",
        "  x = Conv1D(64, 5, activation = 'relu')(x)\n",
        "  x = MaxPooling1D(pool_size = 4)(x)\n",
        "  x = LSTM(units = 300)(x)\n",
        "  x = Dense(1, activation = 'sigmoid')(x)\n",
        "  model = Model(inputs = input_text, outputs = x)\n",
        "  model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics = [f1])\n",
        "\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "  \n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0706 13:00:16.260310 139993834989440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0706 13:00:16.262654 139993834989440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0706 13:00:18.112732 139993834989440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0706 13:00:18.127060 139993834989440 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0706 13:00:18.148937 139993834989440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0706 13:00:18.174609 139993834989440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0706 13:00:18.605708 139993834989440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0706 13:00:18.633549 139993834989440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0706 13:00:18.642990 139993834989440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 100, 1024)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 1024)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 96, 64)            327744    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 300)               438000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 301       \n",
            "=================================================================\n",
            "Total params: 766,045\n",
            "Trainable params: 766,045\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvyyDyKbGhu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "# tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "# strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "\n",
        "# with strategy.scope():\n",
        "# #   model = get_model()\n",
        "#   model.compile(optimizer=opt, \n",
        "#                 loss=\"binary_crossentropy\", \n",
        "#                 metrics = [f1])\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnWxS_dsEKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Batch_Generator:\n",
        "    def __init__(self, trainX, trainY, valX, valY, batch_size = batch_size,\n",
        "                 testX=None, testY=None,shuffle=True):\n",
        "        self.X = {\n",
        "            'train': trainX,\n",
        "            'val': valX,\n",
        "            'test': testX\n",
        "        }\n",
        "        self.Y = {\n",
        "            'train': trainY,\n",
        "            'val': valY,\n",
        "            'test': testY\n",
        "        }\n",
        "        self.cur_idx = {\n",
        "            'train': 0,\n",
        "            'val': 0,\n",
        "            'test': 0\n",
        "        }\n",
        "        self.shuffle = shuffle\n",
        "    def next_batch(self, mode):\n",
        "        n_samples = len(self.X[mode])\n",
        "        if self.shuffle==True:\n",
        "            indices = np.random.permutation(n_samples)\n",
        "        else:\n",
        "            indices = range(n_samples)\n",
        "        while True:\n",
        "            if self.cur_idx[mode] >= (n_samples - batch_size):\n",
        "                if self.shuffle == True:\n",
        "                    indices = np.random.permutation(n_samples)\n",
        "                self.cur_idx[mode] = 0\n",
        "                \n",
        "            x_list = []\n",
        "            y_list = []\n",
        "            batch_end = self.cur_idx[mode] + batch_size\n",
        "            for i in indices[self.cur_idx[mode]:batch_end]:\n",
        "                x_list.append(self.X[mode][i])\n",
        "                y_list.append(self.Y[mode][i])\n",
        "\n",
        "            self.cur_idx[mode] += batch_size\n",
        "            yield np.array(x_list), np.array(y_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "917YUvFu6Vvq",
        "colab_type": "code",
        "outputId": "809b35de-267d-4b32-8b67-b5c051e254c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "checkpoint_path = \"training_elmo/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, verbose=1, save_weights_only=True,\n",
        "    # Save weights, every 5-epochs.\n",
        "    period=10)\n",
        "model.save_weights(checkpoint_path.format(epoch=0))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0706 13:12:20.382901 139993834989440 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49MoeElUvl4l",
        "colab_type": "code",
        "outputId": "358a926b-d276-42ca-ce59-3401229ee8b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "generator = Batch_Generator(train_X, train_y, val_X, val_y)\n",
        "history = model.fit_generator(generator=generator.next_batch('train'), \n",
        "                    steps_per_epoch=50,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback],\n",
        "                    validation_data=generator.next_batch('val'),\n",
        "                    validation_steps=1)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1328 - f1: 0.5471 - val_loss: 0.1805 - val_f1: 0.4583\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 234s 5s/step - loss: 0.1255 - f1: 0.5586 - val_loss: 0.1008 - val_f1: 0.6429\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 234s 5s/step - loss: 0.1277 - f1: 0.6015 - val_loss: 0.1332 - val_f1: 0.4000\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 234s 5s/step - loss: 0.1181 - f1: 0.5880 - val_loss: 0.1490 - val_f1: 0.6486\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 234s 5s/step - loss: 0.1283 - f1: 0.5756 - val_loss: 0.1191 - val_f1: 0.6667\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1252 - f1: 0.5670 - val_loss: 0.0938 - val_f1: 0.6667\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1173 - f1: 0.5896 - val_loss: 0.1390 - val_f1: 0.1176\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 234s 5s/step - loss: 0.1168 - f1: 0.5770 - val_loss: 0.1197 - val_f1: 0.5185\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1283 - f1: 0.5871 - val_loss: 0.1367 - val_f1: 0.6667\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1218 - f1: 0.5991 - val_loss: 0.0881 - val_f1: 0.6857\n",
            "\n",
            "Epoch 00010: saving model to training_elmo/cp-0010.ckpt\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1234 - f1: 0.6278 - val_loss: 0.1053 - val_f1: 0.6286\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1153 - f1: 0.6004 - val_loss: 0.1035 - val_f1: 0.7222\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1137 - f1: 0.6265 - val_loss: 0.1047 - val_f1: 0.4286\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1159 - f1: 0.5935 - val_loss: 0.0885 - val_f1: 0.6341\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1212 - f1: 0.5765 - val_loss: 0.1481 - val_f1: 0.6154\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1190 - f1: 0.6119 - val_loss: 0.1240 - val_f1: 0.4375\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1149 - f1: 0.5986 - val_loss: 0.1231 - val_f1: 0.5641\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1180 - f1: 0.6161 - val_loss: 0.1036 - val_f1: 0.5517\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1199 - f1: 0.6012 - val_loss: 0.0829 - val_f1: 0.5000\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1172 - f1: 0.5879 - val_loss: 0.1272 - val_f1: 0.5517\n",
            "\n",
            "Epoch 00020: saving model to training_elmo/cp-0020.ckpt\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1125 - f1: 0.6235 - val_loss: 0.0927 - val_f1: 0.6061\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1130 - f1: 0.6094 - val_loss: 0.1396 - val_f1: 0.7111\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1143 - f1: 0.6037 - val_loss: 0.1518 - val_f1: 0.5882\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1193 - f1: 0.5961 - val_loss: 0.1697 - val_f1: 0.7500\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1114 - f1: 0.6173 - val_loss: 0.1075 - val_f1: 0.7000\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1130 - f1: 0.6062 - val_loss: 0.1135 - val_f1: 0.7778\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1103 - f1: 0.6173 - val_loss: 0.1241 - val_f1: 0.6500\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1142 - f1: 0.6182 - val_loss: 0.1453 - val_f1: 0.5500\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1146 - f1: 0.5945 - val_loss: 0.1753 - val_f1: 0.5143\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1127 - f1: 0.6234 - val_loss: 0.0850 - val_f1: 0.6875\n",
            "\n",
            "Epoch 00030: saving model to training_elmo/cp-0030.ckpt\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1079 - f1: 0.6364 - val_loss: 0.1285 - val_f1: 0.5714\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1101 - f1: 0.6434 - val_loss: 0.1145 - val_f1: 0.5500\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1130 - f1: 0.6271 - val_loss: 0.1448 - val_f1: 0.5946\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1098 - f1: 0.6250 - val_loss: 0.0638 - val_f1: 0.5833\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1153 - f1: 0.6352 - val_loss: 0.1377 - val_f1: 0.6809\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1154 - f1: 0.6147 - val_loss: 0.0862 - val_f1: 0.6667\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1173 - f1: 0.6102 - val_loss: 0.1203 - val_f1: 0.6471\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1109 - f1: 0.6392 - val_loss: 0.0841 - val_f1: 0.6286\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1133 - f1: 0.6233 - val_loss: 0.1547 - val_f1: 0.6415\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1065 - f1: 0.6326 - val_loss: 0.0849 - val_f1: 0.7368\n",
            "\n",
            "Epoch 00040: saving model to training_elmo/cp-0040.ckpt\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1047 - f1: 0.6534 - val_loss: 0.1329 - val_f1: 0.5000\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1080 - f1: 0.6178 - val_loss: 0.0772 - val_f1: 0.4762\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1160 - f1: 0.6332 - val_loss: 0.1098 - val_f1: 0.7805\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1126 - f1: 0.6137 - val_loss: 0.0932 - val_f1: 0.6000\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1127 - f1: 0.6323 - val_loss: 0.0828 - val_f1: 0.6000\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1164 - f1: 0.6269 - val_loss: 0.1109 - val_f1: 0.5517\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1136 - f1: 0.6303 - val_loss: 0.0913 - val_f1: 0.6486\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1123 - f1: 0.6086 - val_loss: 0.1146 - val_f1: 0.6207\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1137 - f1: 0.6358 - val_loss: 0.1198 - val_f1: 0.6957\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1071 - f1: 0.6522 - val_loss: 0.1203 - val_f1: 0.6222\n",
            "\n",
            "Epoch 00050: saving model to training_elmo/cp-0050.ckpt\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1144 - f1: 0.6230 - val_loss: 0.0816 - val_f1: 0.7586\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1180 - f1: 0.6283 - val_loss: 0.1212 - val_f1: 0.5946\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1085 - f1: 0.6241 - val_loss: 0.1076 - val_f1: 0.7000\n",
            "Epoch 54/100\n",
            "40/50 [=======================>......] - ETA: 46s - loss: 0.1059 - f1: 0.6424"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-8f6156e82195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_steps=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWHLsneJqUpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"Naive_weights_elmo.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKpwM69m6nFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "1300000/512\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdDXPsTR_42n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator2 = Batch_Generator(trainX=None, trainY=None, valX=val_X, valY=val_y, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE7-xXBWqAjL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e825e85-a88f-4989-e041-e49f8361d3a3"
      },
      "source": [
        "predict_val_y = model.predict_generator(generator2.next_batch('val'), steps=50, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 228s 5s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGnXGmuLizt-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b0f79089-9914-4b23-97a7-fa55f7ab8ade"
      },
      "source": [
        "f1_list = []\n",
        "for thresh in np.arange(0.1, 0.901, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    f1 = metrics.f1_score(val_y[:12800], (predict_val_y>thresh).astype(int))\n",
        "    f1_list.append(f1)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, f1))\n",
        "    \n",
        "print(\"max f1: \", max(f1_list))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score at threshold 0.1 is 0.5606595995288575\n",
            "F1 score at threshold 0.11 is 0.5705024311183144\n",
            "F1 score at threshold 0.12 is 0.5831244778613199\n",
            "F1 score at threshold 0.13 is 0.5946643717728055\n",
            "F1 score at threshold 0.14 is 0.6000883782589483\n",
            "F1 score at threshold 0.15 is 0.6072398190045248\n",
            "F1 score at threshold 0.16 is 0.6136048125867654\n",
            "F1 score at threshold 0.17 is 0.6223908918406073\n",
            "F1 score at threshold 0.18 is 0.6231397023523764\n",
            "F1 score at threshold 0.19 is 0.6254863813229572\n",
            "F1 score at threshold 0.2 is 0.6329365079365079\n",
            "F1 score at threshold 0.21 is 0.6377396569122099\n",
            "F1 score at threshold 0.22 is 0.6424180327868853\n",
            "F1 score at threshold 0.23 is 0.6416275430359937\n",
            "F1 score at threshold 0.24 is 0.6422505307855627\n",
            "F1 score at threshold 0.25 is 0.6426264800861141\n",
            "F1 score at threshold 0.26 is 0.6419618528610354\n",
            "F1 score at threshold 0.27 is 0.642343836373687\n",
            "F1 score at threshold 0.28 is 0.641025641025641\n",
            "F1 score at threshold 0.29 is 0.6407219402143258\n",
            "F1 score at threshold 0.3 is 0.6422438465941614\n",
            "F1 score at threshold 0.31 is 0.6396292004634995\n",
            "F1 score at threshold 0.32 is 0.6392961876832844\n",
            "F1 score at threshold 0.33 is 0.6338278931750742\n",
            "F1 score at threshold 0.34 is 0.631578947368421\n",
            "F1 score at threshold 0.35 is 0.6340579710144928\n",
            "F1 score at threshold 0.36 is 0.6349206349206349\n",
            "F1 score at threshold 0.37 is 0.6346272335181763\n",
            "F1 score at threshold 0.38 is 0.6272557560672058\n",
            "F1 score at threshold 0.39 is 0.6203411244472521\n",
            "F1 score at threshold 0.4 is 0.6177409061901723\n",
            "F1 score at threshold 0.41 is 0.6168705730843529\n",
            "F1 score at threshold 0.42 is 0.6122715404699739\n",
            "F1 score at threshold 0.43 is 0.6105263157894737\n",
            "F1 score at threshold 0.44 is 0.6118115461181155\n",
            "F1 score at threshold 0.45 is 0.6135298057602143\n",
            "F1 score at threshold 0.46 is 0.6151761517615176\n",
            "F1 score at threshold 0.47 is 0.6117166212534061\n",
            "F1 score at threshold 0.48 is 0.6126373626373626\n",
            "F1 score at threshold 0.49 is 0.6097222222222222\n",
            "F1 score at threshold 0.5 is 0.6097902097902097\n",
            "F1 score at threshold 0.51 is 0.6039603960396039\n",
            "F1 score at threshold 0.52 is 0.5977175463623394\n",
            "F1 score at threshold 0.53 is 0.5905172413793103\n",
            "F1 score at threshold 0.54 is 0.5847272727272728\n",
            "F1 score at threshold 0.55 is 0.5764705882352942\n",
            "F1 score at threshold 0.56 is 0.5735512630014858\n",
            "F1 score at threshold 0.57 is 0.5660660660660661\n",
            "F1 score at threshold 0.58 is 0.5649546827794562\n",
            "F1 score at threshold 0.59 is 0.5583524027459954\n",
            "F1 score at threshold 0.6 is 0.5571757482732157\n",
            "F1 score at threshold 0.61 is 0.5426114151681001\n",
            "F1 score at threshold 0.62 is 0.5375494071146245\n",
            "F1 score at threshold 0.63 is 0.5286624203821656\n",
            "F1 score at threshold 0.64 is 0.5225080385852089\n",
            "F1 score at threshold 0.65 is 0.5158150851581509\n",
            "F1 score at threshold 0.66 is 0.5118949958982772\n",
            "F1 score at threshold 0.67 is 0.49875724937862476\n",
            "F1 score at threshold 0.68 is 0.49456975772765244\n",
            "F1 score at threshold 0.69 is 0.48258283772302457\n",
            "F1 score at threshold 0.7 is 0.47119518486672396\n",
            "F1 score at threshold 0.71 is 0.45818815331010454\n",
            "F1 score at threshold 0.72 is 0.44601769911504424\n",
            "F1 score at threshold 0.73 is 0.43532560214094557\n",
            "F1 score at threshold 0.74 is 0.42105263157894735\n",
            "F1 score at threshold 0.75 is 0.40478380864765406\n",
            "F1 score at threshold 0.76 is 0.3850467289719627\n",
            "F1 score at threshold 0.77 is 0.3696682464454976\n",
            "F1 score at threshold 0.78 is 0.34715525554484095\n",
            "F1 score at threshold 0.79 is 0.32908912830558273\n",
            "F1 score at threshold 0.8 is 0.3220675944333996\n",
            "F1 score at threshold 0.81 is 0.2886178861788618\n",
            "F1 score at threshold 0.82 is 0.25598335067637873\n",
            "F1 score at threshold 0.83 is 0.20452099031216361\n",
            "F1 score at threshold 0.84 is 0.15795328142380421\n",
            "F1 score at threshold 0.85 is 0.1185860889395667\n",
            "F1 score at threshold 0.86 is 0.05680473372781065\n",
            "F1 score at threshold 0.87 is 0.024183796856106412\n",
            "F1 score at threshold 0.88 is 0.0\n",
            "F1 score at threshold 0.89 is 0.0\n",
            "F1 score at threshold 0.9 is 0.0\n",
            "max f1:  0.6426264800861141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig2hbqH8CCwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}