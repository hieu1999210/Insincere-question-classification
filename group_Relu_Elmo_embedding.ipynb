{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "group_Relu_Elmo_embedding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hieu1999210/Insincere-question-classification/blob/master/group_Relu_Elmo_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndTYK0Paz9Cc",
        "colab_type": "code",
        "outputId": "007aa0d6-21b2-4137-88e5-a8b084869083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!pip install h5py pyyaml\n",
        "# !pip install tf_nightly"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJnknIR50QL6",
        "colab_type": "code",
        "outputId": "86cd4579-7ecd-4b34-c5ee-06041c46cdc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeXb870NbiBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNqTc7XXbrkB",
        "colab_type": "text"
      },
      "source": [
        "### Load and preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcyBknnpbwy7",
        "colab_type": "code",
        "outputId": "a9b096f0-f1ac-4711-839e-ec60fa312a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# mount hieu.kaggle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=False)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsR9l5TidLEN",
        "colab_type": "code",
        "outputId": "5c385337-a286-46fe-91af-8029b1de7554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd \"/gdrive/My Drive/nlp\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/nlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo-oFoZB7MkI",
        "colab_type": "code",
        "outputId": "ea3f0dbe-05e8-4da4-8e7f-fb8c07cbd6dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  embeddings  training_elmo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnoGR-5wb59R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "\n",
        "path_train = \"data/train.csv\"\n",
        "path_test = \"data/test.csv\"\n",
        "train = pd.read_csv(path_train)\n",
        "test = pd.read_csv(path_test)\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1396XLvcLM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val = train_test_split(train, test_size = 0.01, random_state = 2019) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4jsjFEMnZxI",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Some parameters\n",
        "embedding_dim = 1024 #@param {type:\"integer\"}\n",
        "\n",
        "vocab_size = 50000 #@param {type:\"integer\"}\n",
        "\n",
        "question_length = 100 #@param {type:\"integer\"}\n",
        "\n",
        "batch_size = 256 #@param {type:\"integer\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usF0cVqynQDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## fill up the missing values\n",
        "train_X = train[\"question_text\"].fillna(\"_na_\").values\n",
        "val_X = val[\"question_text\"].fillna(\"_na_\").values\n",
        "test_X = test[\"question_text\"].fillna(\"_na_\").values\n",
        "\n",
        "#Tokenize the sentences\n",
        "# tokenizer = Tokenizer(num_words = max_features)\n",
        "# tokenizer.fit_on_texts(list(train_X))\n",
        "# train_X = tokenizer.texts_to_sequences(train_X)\n",
        "# val_X = tokenizer.texts_to_sequences(val_X)\n",
        "# test_X = tokenizer.texts_to_sequences(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdEQ1HDun3_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #padding\n",
        "# train_X = pad_sequences(train_X, maxlen = maxlen)\n",
        "# val_X = pad_sequences(val_X, maxlen = maxlen)\n",
        "# test_X = pad_sequences(test_X, maxlen = maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjLCoQMu1eCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = train['target'].values\n",
        "val_y = val['target'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_UXCL0TcOBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QvXhqjBnNuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#padding\n",
        "\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "def padding(sentences, maxlen= question_length, pad_word = \"\"):\n",
        "    \"\"\"\n",
        "    padding sentences and truncating if necessary\n",
        "    \"\"\"\n",
        "    Sentences = [text_to_word_sequence(sentence, lower = False, split=' ') for sentence in sentences]\n",
        "#     lengths = []\n",
        "    for i, sentence in enumerate(Sentences):\n",
        "#         lengths.append(len(sentence))\n",
        "        if len(sentence) > maxlen:\n",
        "            Sentences[i] = sentence[:maxlen]\n",
        "        else:\n",
        "            for _ in range(maxlen - len(sentence)):\n",
        "                sentence.append(pad_word)\n",
        "    return Sentences\n",
        "\n",
        "train_X = padding(train_X)\n",
        "val_X = padding(val_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYIba4b-Aaf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to run on tpu\n",
        "\n",
        "\n",
        "# def train_input_fn(x_train=train_X, y_train=train_y, batch_size=batch_size):\n",
        "#     # Convert the inputs to a Dataset.\n",
        "#     dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "# # Shuffle, repeat, and batch the examples.\n",
        "#     dataset = dataset.cache()\n",
        "#     dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)\n",
        "#     dataset = dataset.repeat()\n",
        "#     dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "# # Return the dataset.\n",
        "#     return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GichFDCrAhOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tpu_val = train_input_fn(val_X, val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc2OvkqzBa9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tpu_train = train_input_fn(train_X, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmPXHrG-eazK",
        "colab_type": "code",
        "outputId": "585c8987-2fef-4241-e377-2be72d96fc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test padding\n",
        "count = 0\n",
        "for sentence in val_X:\n",
        "    if len(sentence) != 100:\n",
        "        count +=1\n",
        "count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQuAlFb5BEVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to enable  tpu\n",
        "\n",
        "\n",
        "# import sys\n",
        "\n",
        "# # sys.path.append('bert/')\n",
        "\n",
        "# from __future__ import absolute_import\n",
        "# from __future__ import division\n",
        "# from __future__ import print_function\n",
        "\n",
        "# import codecs\n",
        "# import collections\n",
        "# import json\n",
        "# import re\n",
        "# import os\n",
        "# import pprint\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "\n",
        "# assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "# TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "# print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "# with tf.Session(TPU_ADDRESS) as session:\n",
        "#   print('TPU devices:')\n",
        "#   pprint.pprint(session.list_devices())\n",
        "\n",
        "#   # Upload credentials to TPU.\n",
        "#   with open('/content/adc.json', 'r') as f:\n",
        "#     auth_info = json.load(f)\n",
        "#   tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "#   # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBgTX0o6ryHt",
        "colab_type": "text"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHsYCxxXsEMM",
        "colab_type": "text"
      },
      "source": [
        "import elmo \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWSkYnpRct8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndYG6HBlip1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICrNegJHkJD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def ElmoEmbedding(x):\n",
        "    return elmo(inputs={\"tokens\": tf.squeeze(tf.cast(x,tf.string)),\n",
        "                        \"sequence_len\": tf.constant(batch_size*[question_length])},\n",
        "                signature=\"tokens\",\n",
        "                as_dict=True)[\"elmo\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG8Qoo3KPXND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(y_true * y_pred)\n",
        "        possible_positives = K.sum(y_true)\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(y_true * y_pred)\n",
        "        predicted_positives = K.sum(y_pred)\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    \n",
        "    Y_pred = tf.cast(tf.less(0.3, y_pred), tf.float32)\n",
        "    \n",
        "    precision = precision(y_true, Y_pred)\n",
        "    recall = recall(y_true, Y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro9u2r19FPZy",
        "colab_type": "code",
        "outputId": "193e2c9d-0cb0-4ffb-aff8-bd045ea4d4fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.keras.__version__)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayc_EjMHlJrb",
        "colab_type": "code",
        "outputId": "e58f07da-4464-4cdc-c7b5-05ab98398565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Lambda, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "def build_model ():\n",
        "# model = Sequential()\n",
        "# model.add(Lambda(ElmoEmbedding, output_shape = (1024, )))\n",
        "# #model.add(Embedding(50000, 300, input_length=100, trainable=True))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Conv1D(64, 5, activation='relu'))\n",
        "# model.add(MaxPooling1D(pool_size=4))\n",
        "# model.add(LSTM(300))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# model.build(input_shape = (None, 100, 1024))\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "  input_text = Input(shape=(question_length,) , dtype = tf.string)\n",
        "  embedding = Lambda(ElmoEmbedding, output_shape=(question_length, embedding_dim))(input_text)\n",
        "  x = Dropout(rate = 0.2)(embedding)\n",
        "  x = Conv1D(64, 5, activation = 'relu')(x)\n",
        "  x = MaxPooling1D(pool_size = 4)(x)\n",
        "  x = LSTM(units = 300)(x)\n",
        "  x = Dense(1, activation = 'sigmoid')(x)\n",
        "  model = Model(inputs = input_text, outputs = x)\n",
        "  model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics = [f1])\n",
        "\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "  \n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0710 14:36:58.430854 140009667860352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0710 14:36:58.433212 140009667860352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0710 14:37:00.660320 140009667860352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0710 14:37:00.673707 140009667860352 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0710 14:37:00.703375 140009667860352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0710 14:37:00.732737 140009667860352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0710 14:37:01.183074 140009667860352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0710 14:37:01.213315 140009667860352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0710 14:37:01.224561 140009667860352 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 100, 1024)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 1024)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 96, 64)            327744    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 300)               438000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 301       \n",
            "=================================================================\n",
            "Total params: 766,045\n",
            "Trainable params: 766,045\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvyyDyKbGhu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "# tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "# strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "\n",
        "# with strategy.scope():\n",
        "# #   model = get_model()\n",
        "#   model.compile(optimizer=opt, \n",
        "#                 loss=\"binary_crossentropy\", \n",
        "#                 metrics = [f1])\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iPbLt5oR7Kt",
        "colab_type": "text"
      },
      "source": [
        "#Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnWxS_dsEKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Batch_Generator:\n",
        "    def __init__(self, trainX, trainY, valX, valY, batch_size = batch_size,\n",
        "                 testX=None, testY=None,shuffle=True):\n",
        "        self.X = {\n",
        "            'train': trainX,\n",
        "            'val': valX,\n",
        "            'test': testX\n",
        "        }\n",
        "        self.Y = {\n",
        "            'train': trainY,\n",
        "            'val': valY,\n",
        "            'test': testY\n",
        "        }\n",
        "        self.cur_idx = {\n",
        "            'train': 0,\n",
        "            'val': 0,\n",
        "            'test': 0\n",
        "        }\n",
        "        self.shuffle = shuffle\n",
        "    def next_batch(self, mode):\n",
        "        n_samples = len(self.X[mode])\n",
        "        if self.shuffle==True:\n",
        "            indices = np.random.permutation(n_samples)\n",
        "        else:\n",
        "            indices = range(n_samples)\n",
        "        while True:\n",
        "            if self.cur_idx[mode] >= (n_samples - batch_size):\n",
        "                if self.shuffle == True:\n",
        "                    indices = np.random.permutation(n_samples)\n",
        "                self.cur_idx[mode] = 0\n",
        "                \n",
        "            x_list = []\n",
        "            y_list = []\n",
        "            batch_end = self.cur_idx[mode] + batch_size\n",
        "            for i in indices[self.cur_idx[mode]:batch_end]:\n",
        "                x_list.append(self.X[mode][i])\n",
        "                y_list.append(self.Y[mode][i])\n",
        "\n",
        "            self.cur_idx[mode] += batch_size\n",
        "            yield np.array(x_list), np.array(y_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "917YUvFu6Vvq",
        "colab_type": "code",
        "outputId": "3e8b3a88-9d7b-44d5-b2ed-1535babe99fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "checkpoint_path = \"training_elmo/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path, verbose=1, save_weights_only=True,\n",
        "    # Save weights, every 5-epochs.\n",
        "    period=10)\n",
        "# model.save_weights(checkpoint_path.format(epoch=0))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0710 14:37:15.184892 140009667860352 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49MoeElUvl4l",
        "colab_type": "code",
        "outputId": "358a926b-d276-42ca-ce59-3401229ee8b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "generator = Batch_Generator(train_X, train_y, val_X, val_y)\n",
        "history = model.fit_generator(generator=generator.next_batch('train'), \n",
        "                    steps_per_epoch=50,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback],\n",
        "                    validation_data=generator.next_batch('val'),\n",
        "                    validation_steps=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1328 - f1: 0.5471 - val_loss: 0.1805 - val_f1: 0.4583\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 234s 5s/step - loss: 0.1255 - f1: 0.5586 - val_loss: 0.1008 - val_f1: 0.6429\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 234s 5s/step - loss: 0.1277 - f1: 0.6015 - val_loss: 0.1332 - val_f1: 0.4000\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 234s 5s/step - loss: 0.1181 - f1: 0.5880 - val_loss: 0.1490 - val_f1: 0.6486\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 234s 5s/step - loss: 0.1283 - f1: 0.5756 - val_loss: 0.1191 - val_f1: 0.6667\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1252 - f1: 0.5670 - val_loss: 0.0938 - val_f1: 0.6667\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1173 - f1: 0.5896 - val_loss: 0.1390 - val_f1: 0.1176\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 234s 5s/step - loss: 0.1168 - f1: 0.5770 - val_loss: 0.1197 - val_f1: 0.5185\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1283 - f1: 0.5871 - val_loss: 0.1367 - val_f1: 0.6667\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1218 - f1: 0.5991 - val_loss: 0.0881 - val_f1: 0.6857\n",
            "\n",
            "Epoch 00010: saving model to training_elmo/cp-0010.ckpt\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1234 - f1: 0.6278 - val_loss: 0.1053 - val_f1: 0.6286\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1153 - f1: 0.6004 - val_loss: 0.1035 - val_f1: 0.7222\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1137 - f1: 0.6265 - val_loss: 0.1047 - val_f1: 0.4286\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1159 - f1: 0.5935 - val_loss: 0.0885 - val_f1: 0.6341\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1212 - f1: 0.5765 - val_loss: 0.1481 - val_f1: 0.6154\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1190 - f1: 0.6119 - val_loss: 0.1240 - val_f1: 0.4375\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1149 - f1: 0.5986 - val_loss: 0.1231 - val_f1: 0.5641\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1180 - f1: 0.6161 - val_loss: 0.1036 - val_f1: 0.5517\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1199 - f1: 0.6012 - val_loss: 0.0829 - val_f1: 0.5000\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1172 - f1: 0.5879 - val_loss: 0.1272 - val_f1: 0.5517\n",
            "\n",
            "Epoch 00020: saving model to training_elmo/cp-0020.ckpt\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1125 - f1: 0.6235 - val_loss: 0.0927 - val_f1: 0.6061\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1130 - f1: 0.6094 - val_loss: 0.1396 - val_f1: 0.7111\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1143 - f1: 0.6037 - val_loss: 0.1518 - val_f1: 0.5882\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1193 - f1: 0.5961 - val_loss: 0.1697 - val_f1: 0.7500\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1114 - f1: 0.6173 - val_loss: 0.1075 - val_f1: 0.7000\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1130 - f1: 0.6062 - val_loss: 0.1135 - val_f1: 0.7778\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1103 - f1: 0.6173 - val_loss: 0.1241 - val_f1: 0.6500\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1142 - f1: 0.6182 - val_loss: 0.1453 - val_f1: 0.5500\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1146 - f1: 0.5945 - val_loss: 0.1753 - val_f1: 0.5143\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1127 - f1: 0.6234 - val_loss: 0.0850 - val_f1: 0.6875\n",
            "\n",
            "Epoch 00030: saving model to training_elmo/cp-0030.ckpt\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1079 - f1: 0.6364 - val_loss: 0.1285 - val_f1: 0.5714\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1101 - f1: 0.6434 - val_loss: 0.1145 - val_f1: 0.5500\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1130 - f1: 0.6271 - val_loss: 0.1448 - val_f1: 0.5946\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1098 - f1: 0.6250 - val_loss: 0.0638 - val_f1: 0.5833\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1153 - f1: 0.6352 - val_loss: 0.1377 - val_f1: 0.6809\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1154 - f1: 0.6147 - val_loss: 0.0862 - val_f1: 0.6667\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1173 - f1: 0.6102 - val_loss: 0.1203 - val_f1: 0.6471\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1109 - f1: 0.6392 - val_loss: 0.0841 - val_f1: 0.6286\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1133 - f1: 0.6233 - val_loss: 0.1547 - val_f1: 0.6415\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1065 - f1: 0.6326 - val_loss: 0.0849 - val_f1: 0.7368\n",
            "\n",
            "Epoch 00040: saving model to training_elmo/cp-0040.ckpt\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1047 - f1: 0.6534 - val_loss: 0.1329 - val_f1: 0.5000\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1080 - f1: 0.6178 - val_loss: 0.0772 - val_f1: 0.4762\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1160 - f1: 0.6332 - val_loss: 0.1098 - val_f1: 0.7805\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1126 - f1: 0.6137 - val_loss: 0.0932 - val_f1: 0.6000\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1127 - f1: 0.6323 - val_loss: 0.0828 - val_f1: 0.6000\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1164 - f1: 0.6269 - val_loss: 0.1109 - val_f1: 0.5517\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1136 - f1: 0.6303 - val_loss: 0.0913 - val_f1: 0.6486\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1123 - f1: 0.6086 - val_loss: 0.1146 - val_f1: 0.6207\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1137 - f1: 0.6358 - val_loss: 0.1198 - val_f1: 0.6957\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1071 - f1: 0.6522 - val_loss: 0.1203 - val_f1: 0.6222\n",
            "\n",
            "Epoch 00050: saving model to training_elmo/cp-0050.ckpt\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 235s 5s/step - loss: 0.1144 - f1: 0.6230 - val_loss: 0.0816 - val_f1: 0.7586\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1180 - f1: 0.6283 - val_loss: 0.1212 - val_f1: 0.5946\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 236s 5s/step - loss: 0.1085 - f1: 0.6241 - val_loss: 0.1076 - val_f1: 0.7000\n",
            "Epoch 54/100\n",
            "40/50 [=======================>......] - ETA: 46s - loss: 0.1059 - f1: 0.6424"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-8f6156e82195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_steps=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWHLsneJqUpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"training_elmo/cp-0050.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKpwM69m6nFm",
        "colab_type": "code",
        "outputId": "cb3cdc4f-443c-40ba-de5f-755e8ff53a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_y.shape\n",
        "13062/256"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.0234375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEDHB4RrbCQQ",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdDXPsTR_42n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator2 = Batch_Generator(trainX=None, trainY=None, valX=val_X, valY=val_y, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE7-xXBWqAjL",
        "colab_type": "code",
        "outputId": "b752106b-770e-4fbb-a23a-fa5dfc04a293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict_val_y = model.predict_generator(generator2.next_batch('val'), steps=50, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=1)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 229s 5s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGnXGmuLizt-",
        "colab_type": "code",
        "outputId": "378f3b63-b698-47f9-9df8-578dba25aa45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "scores = []\n",
        "thresholds = np.arange(0.1, 0.901, 0.01)\n",
        "\n",
        "for thresh in thresholds:\n",
        "    thresh = np.round(thresh, 2)\n",
        "    score = metrics.f1_score(val_y[:12800], (predict_val_y>thresh).astype(int))\n",
        "    scores.append(score)\n",
        "#     print(\"F1 score at threshold {0} is {1}\".format(thresh, score))\n",
        "\n",
        "plt.plot(thresholds, scores)\n",
        "# plt.plot(history.history['val_f1'])\n",
        "plt.title('model performance')\n",
        "plt.ylabel('f1 score')\n",
        "plt.xlabel('threshold')\n",
        "# plt.legend(['train','val'], loc='upper left')\n",
        "\n",
        "plt.show()\n",
        "print(\"Best F1 score: {b:.4f} (thresshold {a: .2f})\".format(b=max(scores), \n",
        "      a=thresholds[scores.index(max(scores))]))\n",
        "\n",
        "# f1_list = []\n",
        "# for thresh in np.arange(0.1, 0.901, 0.01):\n",
        "#     thresh = np.round(thresh, 2)\n",
        "#     f1 = metrics.f1_score(val_y[:12800], (predict_val_y>thresh).astype(int))\n",
        "#     f1_list.append(f1)\n",
        "# #     print(\"F1 score at threshold {0} is {1}\".format(thresh, f1))\n",
        "    \n",
        "# print(\"max f1: \", max(f1_list))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKgoiIlJFRUFERKqoKIiISJX/D8bwaAVv4PTVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Best F1 score: 0.6528 (thresshold  0.30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbcN1V3INWuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig2hbqH8CCwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}